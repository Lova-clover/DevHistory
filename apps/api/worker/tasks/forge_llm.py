import sys
sys.path.insert(0, '/app/packages/merge_forge')
sys.path.insert(0, '/app/packages/merge_styler')
sys.path.insert(0, '/app/packages/merge_core')

from worker.celery_app import celery_app
from app.database import SessionLocal
from app.models.user import User
from app.models.weekly_summary import WeeklySummary
from app.models.repo import Repo
from app.models.style_profile import StyleProfile
from app.models.generated_content import GeneratedContent
from app.models.llm_credential import LlmCredential
from app.crypto import decrypt_value
from datetime import datetime


def _get_user_llm_key(db, user_id: str) -> tuple[str | None, str]:
    """Return (api_key, model) for a user. Falls back to None (env var)."""
    cred = db.query(LlmCredential).filter(LlmCredential.user_id == user_id).first()
    if cred and cred.encrypted_api_key:
        try:
            api_key = decrypt_value(cred.encrypted_api_key)
            cred.last_used_at = datetime.utcnow()
            db.commit()
            return api_key, cred.model or "gpt-4o-mini"
        except Exception:
            pass
    return None, "gpt-4o-mini"


@celery_app.task
def generate_weekly_report_llm(user_id: str, weekly_summary_id: str):
    """Generate LLM-based weekly report."""
    db = SessionLocal()
    try:
        user = db.query(User).filter(User.id == user_id).first()
        if not user:
            return {"error": "User not found"}
        
        weekly_summary = db.query(WeeklySummary).filter(WeeklySummary.id == weekly_summary_id).first()
        if not weekly_summary:
            return {"error": "Weekly summary not found"}
        
        style_profile = db.query(StyleProfile).filter(StyleProfile.user_id == user_id).first()
        if not style_profile:
            style_profile = StyleProfile(
                user_id=user_id,
                language="ko",
                tone="technical",
                blog_structure=["Summary", "What I did", "Learned", "Next"],
                report_structure=["Summary", "What I did", "Learned", "Next"],
                extra_instructions=None
            )
            db.add(style_profile)
            db.commit()
            db.refresh(style_profile)
        
        api_key, model = _get_user_llm_key(db, user_id)

        from merge_forge.weekly_report import generate_weekly_report
        content = generate_weekly_report(user, weekly_summary, style_profile, api_key=api_key, model=model)
        
        generated = GeneratedContent(
            user_id=user_id,
            content_type="weekly_report",
            source_ref=f"weekly:{weekly_summary_id}",
            content=content,
            status="completed",
        )
        db.add(generated)
        db.commit()
        
        return {"status": "success", "user_id": user_id, "weekly_id": weekly_summary_id, "content_id": str(generated.id)}
    except Exception as e:
        return {"error": str(e)}
    finally:
        db.close()


@celery_app.task
def generate_repo_blog_llm(user_id: str, repo_id: str):
    """Generate LLM-based repo blog post."""
    db = SessionLocal()
    try:
        user = db.query(User).filter(User.id == user_id).first()
        if not user:
            return {"error": "User not found"}
        
        repo = db.query(Repo).filter(Repo.id == repo_id).first()
        if not repo:
            return {"error": "Repo not found"}
        
        style_profile = db.query(StyleProfile).filter(StyleProfile.user_id == user_id).first()
        if not style_profile:
            style_profile = StyleProfile(
                user_id=user_id,
                language="ko",
                tone="technical",
                blog_structure=["Intro", "Problem", "Approach", "Result", "Next"],
                report_structure=["Summary", "What I did", "Learned", "Next"],
                extra_instructions=None
            )
            db.add(style_profile)
            db.commit()
            db.refresh(style_profile)
        
        api_key, model = _get_user_llm_key(db, user_id)

        from merge_forge.repo_blog import generate_repo_blog
        content = generate_repo_blog(user, repo, style_profile, api_key=api_key, model=model)
        
        generated = GeneratedContent(
            user_id=user_id,
            content_type="repo_blog",
            source_ref=f"repo:{repo_id}",
            content=content,
            status="completed",
        )
        db.add(generated)
        db.commit()
        
        return {"status": "success", "user_id": user_id, "repo_id": repo_id, "content_id": str(generated.id)}
    except Exception as e:
        return {"error": str(e)}
    finally:
        db.close()


@celery_app.task
def generate_content_llm(user_id: str, content_id: str):
    """Generic content generation task (used by POST /content and /regenerate)."""
    db = SessionLocal()
    try:
        content = db.query(GeneratedContent).filter(GeneratedContent.id == content_id).first()
        if not content:
            return {"error": "Content record not found"}

        user = db.query(User).filter(User.id == user_id).first()
        if not user:
            content.status = "failed"
            content.error_message = "User not found"
            db.commit()
            return {"error": "User not found"}

        # Mark as generating
        content.status = "generating"
        content.started_at = datetime.utcnow()
        db.commit()

        # Read metadata stored by the router
        meta = content.metadata or {}
        context_text = meta.get("context") or ""
        use_style = meta.get("use_style_profile", True)
        date_start = meta.get("date_range_start")
        date_end = meta.get("date_range_end")

        # Resolve style profile if requested
        style_profile = None
        if use_style:
            style_profile = db.query(StyleProfile).filter(StyleProfile.user_id == user_id).first()

        # Build LLM prompts
        system_prompt = _build_content_system_prompt(content.content_type, style_profile)
        user_prompt = _build_content_user_prompt(
            content.content_type, content.title, context_text, date_start, date_end
        )

        # Resolve API key (BYO or fallback)
        api_key, model = _get_user_llm_key(db, user_id)

        from merge_core.llm import generate_text
        generated_text = generate_text(
            system_prompt, user_prompt, model=model, api_key=api_key
        )

        now = datetime.utcnow()
        content.content = generated_text
        content.status = "completed"
        content.updated_at = now
        content.completed_at = now
        if content.started_at:
            content.generation_seconds = (now - content.started_at).total_seconds()
        db.commit()

        return {"status": "success", "content_id": content_id}
    except Exception as e:
        # Best-effort: mark failed
        try:
            content = db.query(GeneratedContent).filter(GeneratedContent.id == content_id).first()
            if content:
                content.status = "failed"
                content.error_message = str(e)[:2000]
                content.updated_at = datetime.utcnow()
                db.commit()
        except Exception:
            pass
        return {"error": str(e)}
    finally:
        db.close()


# â”€â”€ Prompt helpers for generic content generation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _build_content_system_prompt(content_type: str, style_profile=None) -> str:
    parts = [
        "ë„ˆëŠ” ì‚¬ìš©ìì˜ ê°œë°œ í™œë™ì„ ë©‹ì§„ ê¸€ë¡œ ì •ë¦¬í•´ì£¼ëŠ” AI í¸ì§‘ìë‹¤.",
        f"ìƒì„±í•  ì½˜í…ì¸  ìœ í˜•: {content_type}",
    ]
    if style_profile:
        parts.append(f"ì¶œë ¥ ì–¸ì–´: {style_profile.language}")
        parts.append(f"í†¤: {style_profile.tone}")
        if content_type in ("blog_post",) and style_profile.blog_structure:
            parts.append("ê¸€ êµ¬ì¡°: " + " > ".join(style_profile.blog_structure))
        if content_type in ("report", "summary") and style_profile.report_structure:
            parts.append("ë¦¬í¬íŠ¸ êµ¬ì¡°: " + " > ".join(style_profile.report_structure))
        if style_profile.extra_instructions:
            parts.append(f"ì¶”ê°€ ì§€ì¹¨: {style_profile.extra_instructions}")
    else:
        parts.append("ì¶œë ¥ ì–¸ì–´: ko")
        parts.append("í†¤: technical")
    return "\n".join(parts)


def _build_content_user_prompt(
    content_type: str, title: str, context: str,
    date_start: str | None, date_end: str | None,
) -> str:
    lines = []
    if title:
        lines.append(f"ì œëª©: {title}")
    if date_start or date_end:
        lines.append(f"ê¸°ê°„: {date_start or '?'} ~ {date_end or '?'}")
    if context:
        lines.append(f"ì°¸ê³  ë§¥ë½ / ì¶”ê°€ ì§€ì‹œ:\n{context}")
    lines.append("\nìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ Markdown í˜•ì‹ì˜ ê¸€ì„ ì‘ì„±í•´ì¤˜.")
    return "\n".join(lines)


@celery_app.task
def learn_velog_style(user_id: str):
    """Analyze user's Velog posts and learn their writing style."""
    db = SessionLocal()
    try:
        from app.models.blog_post import BlogPost
        from app.models.user_profile import UserProfile
        import httpx
        import feedparser

        # Get user's velog ID
        user_profile = db.query(UserProfile).filter(UserProfile.user_id == user_id).first()
        if not user_profile or not user_profile.velog_id:
            return {"error": "Velog ID not configured"}

        clean_id = user_profile.velog_id.lstrip("@")

        # Fetch RSS with full content
        try:
            resp = httpx.get(f"https://api.velog.io/rss/@{clean_id}", timeout=30.0)
            resp.raise_for_status()
        except Exception as e:
            return {"error": f"Failed to fetch Velog RSS: {str(e)}"}

        feed = feedparser.parse(resp.text)
        if not hasattr(feed, "entries") or len(feed.entries) == 0:
            return {"error": "No blog posts found"}

        # Collect post samples (up to 5 most recent with content)
        samples = []
        for entry in feed.entries[:5]:
            title = entry.get("title", "")
            # RSS description/content contains the post body
            body = entry.get("description", "") or entry.get("content", [{}])[0].get("value", "")
            # Strip HTML tags for cleaner analysis
            import re
            clean_body = re.sub(r"<[^>]+>", "", body)[:2000]
            if clean_body:
                samples.append(f"### {title}\n{clean_body}")

        if not samples:
            return {"error": "No post content available for analysis"}

        combined_samples = "\n\n---\n\n".join(samples)

        # Use LLM to analyze writing style
        api_key, model = _get_user_llm_key(db, user_id)
        from merge_core.llm import generate_text

        system_prompt = """ë„ˆëŠ” ë¸”ë¡œê·¸ ê¸€ì“°ê¸° ìŠ¤íƒ€ì¼ ë¶„ì„ ì „ë¬¸ê°€ë‹¤.
ì‚¬ìš©ìì˜ ë¸”ë¡œê·¸ ê¸€ ìƒ˜í”Œì„ ë¶„ì„í•˜ì—¬, ë‹¤ë¥¸ AIê°€ ì´ ì‚¬ìš©ìì˜ ìŠ¤íƒ€ì¼ë¡œ ê¸€ì„ ì“¸ ìˆ˜ ìˆë„ë¡ í•˜ëŠ” 'ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸'ë¥¼ ìƒì„±í•´ì•¼ í•œë‹¤.

ë¶„ì„í•  í•­ëª©:
1. ë¬¸ì²´/ì–´íˆ¬ (ì¡´ëŒ“ë§/ë°˜ë§, ê²©ì‹ ìˆ˜ì¤€)
2. ê¸€ êµ¬ì¡° íŒ¨í„´ (ì„œë¡ -ë³¸ë¡ -ê²°ë¡ , ì´ë¯¸ì§€ í™œìš©, ì½”ë“œ ë¸”ë¡ ìŠ¤íƒ€ì¼ ë“±)
3. ìì£¼ ì‚¬ìš©í•˜ëŠ” í‘œí˜„ì´ë‚˜ ê´€ìš©êµ¬
4. ê¸°ìˆ  ìš©ì–´ ì‚¬ìš© ë°©ì‹ (í•œê¸€í™” vs ì˜ì–´ ê·¸ëŒ€ë¡œ)
5. ë…ìì™€ì˜ ì†Œí†µ ë°©ì‹ (ì§ˆë¬¸í˜•, ì„¤ëª…í˜• ë“±)
6. íŠ¹ì´í•œ ìŠµê´€ì´ë‚˜ íŒ¨í„´

ê²°ê³¼ë¬¼ì€ ë‹¤ë¥¸ AI ëª¨ë¸ì—ê²Œ ì¤„ 'ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸' í˜•íƒœë¡œ ì‘ì„±í•´ë¼.
"ì´ ì‚¬ìš©ìì˜ ë¸”ë¡œê·¸ ìŠ¤íƒ€ì¼ë¡œ ê¸€ì„ ì‘ì„±í•´ë¼. ìŠ¤íƒ€ì¼ íŠ¹ì„±ì€ ë‹¤ìŒê³¼ ê°™ë‹¤:"ë¡œ ì‹œì‘í•´ë¼.
í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³ , 500ì ë‚´ì™¸ë¡œ ê°„ê²°í•˜ê²Œ ì •ë¦¬í•´ë¼."""

        user_prompt = f"""ë‹¤ìŒì€ ì‚¬ìš©ì @{clean_id}ì˜ ìµœê·¼ ë¸”ë¡œê·¸ ê¸€ {len(samples)}ê°œì…ë‹ˆë‹¤.
ì´ ê¸€ë“¤ì„ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìì˜ ê¸€ì“°ê¸° ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

{combined_samples}"""

        learned_prompt = generate_text(system_prompt, user_prompt, model=model, api_key=api_key)

        # Save to StyleProfile
        style = db.query(StyleProfile).filter(StyleProfile.user_id == user_id).first()
        if not style:
            style = StyleProfile(
                user_id=user_id,
                language="ko",
                tone="technical",
                blog_structure=["Intro", "Problem", "Approach", "Result", "Next"],
                report_structure=["Summary", "What I did", "Learned", "Next"],
            )
            db.add(style)

        style.learned_style_prompt = learned_prompt
        style.learned_at = datetime.utcnow()
        db.commit()

        return {"status": "success", "learned_prompt": learned_prompt}
    except Exception as e:
        return {"error": str(e)}
    finally:
        db.close()


@celery_app.task
def generate_coach_analysis(user_id: str):
    """Analyze user's solved.ac problems and provide coaching insights."""
    db = SessionLocal()
    try:
        from app.models.problem import Problem
        from sqlalchemy import func

        problems = db.query(Problem).filter(Problem.user_id == user_id).all()
        if not problems:
            return {"error": "No solved problems found"}

        # Aggregate stats
        total = len(problems)
        by_level = {}
        all_tags = {}
        for p in problems:
            lvl = p.level or 0
            by_level[lvl] = by_level.get(lvl, 0) + 1
            for tag in (p.tags or []):
                all_tags[tag] = all_tags.get(tag, 0) + 1

        # Sort tags by count
        sorted_tags = sorted(all_tags.items(), key=lambda x: x[1], reverse=True)
        top_tags = sorted_tags[:10]
        weak_tags = [t for t, c in sorted_tags if c <= 2][:10]

        stats_text = f"""ì´ í’€ì´ ìˆ˜: {total}
ë‚œì´ë„ë³„ ë¶„í¬: {dict(sorted(by_level.items()))}
ìì£¼ í‘¸ëŠ” ìœ í˜• (ìƒìœ„ 10): {top_tags}
ì ê²Œ í‘¸ëŠ” ìœ í˜• (2ë¬¸ì œ ì´í•˜): {weak_tags}"""

        api_key, model = _get_user_llm_key(db, user_id)
        from merge_core.llm import generate_text

        system_prompt = """ë„ˆëŠ” ì•Œê³ ë¦¬ì¦˜ ì½”ë”© ì½”ì¹˜ì´ì CS êµìœ¡ ì „ë¬¸ê°€ë‹¤.
ì‚¬ìš©ìì˜ solved.ac ë¬¸ì œ í’€ì´ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë§ì¶¤í˜• ì¡°ì–¸ì„ ì œê³µí•œë‹¤.

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ì‘ì„±í•´ë¼:

## ğŸ† í˜„ì¬ ì‹¤ë ¥ ìš”ì•½
(ì „ì²´ì ì¸ ìˆ˜ì¤€ í‰ê°€)

## ğŸ’ª ê°•ì  ë¶„ì•¼
(ì˜í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ ìœ í˜•ê³¼ ì™œ ê°•ì ì¸ì§€)

## ğŸ¯ ë³´ì™„ì´ í•„ìš”í•œ ë¶„ì•¼
(ë¶€ì¡±í•œ ë¶€ë¶„ê³¼ êµ¬ì²´ì ì¸ ê°œì„  ë°©ë²•)

## ğŸ“š ì¶”ì²œ í•™ìŠµ ë¡œë“œë§µ
(ë‹¨ê³„ë³„ë¡œ ì–´ë–¤ ìœ í˜•ì˜ ë¬¸ì œë¥¼ í’€ë©´ ì¢‹ì„ì§€)

## ğŸ’¡ ì˜¤ëŠ˜ì˜ ë„ì „ ê³¼ì œ
(ë°”ë¡œ ë„ì „í•  ë§Œí•œ ë¬¸ì œ ìœ í˜• 3ê°€ì§€)

í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³ , ì‹¤ì§ˆì ì´ê³  êµ¬ì²´ì ì¸ ì¡°ì–¸ì„ í•´ë¼."""

        user_prompt = f"""ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ì•Œê³ ë¦¬ì¦˜ ë¬¸ì œ í’€ì´ í†µê³„ì…ë‹ˆë‹¤:

{stats_text}

ì´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§ì¶¤í˜• ì½”ë”© ì½”ì¹˜ ë¶„ì„ì„ í•´ì£¼ì„¸ìš”."""

        analysis = generate_text(system_prompt, user_prompt, model=model, api_key=api_key)

        # Store as generated content
        content = GeneratedContent(
            user_id=user_id,
            content_type="coach_analysis",
            title="ì•Œê³ ë¦¬ì¦˜ ì½”ì¹­ ë¶„ì„",
            content=analysis,
            status="completed",
            metadata={"total_problems": total, "top_tags": dict(top_tags)},
        )
        db.add(content)
        db.commit()

        return {"status": "success", "content_id": str(content.id), "analysis": analysis}
    except Exception as e:
        return {"error": str(e)}
    finally:
        db.close()


@celery_app.task
def generate_coach_quiz(user_id: str, topic: str = ""):
    """Generate a coding quiz targeting weak areas."""
    db = SessionLocal()
    try:
        from app.models.problem import Problem

        problems = db.query(Problem).filter(Problem.user_id == user_id).all()
        all_tags = {}
        for p in problems:
            for tag in (p.tags or []):
                all_tags[tag] = all_tags.get(tag, 0) + 1

        sorted_tags = sorted(all_tags.items(), key=lambda x: x[1])
        weak_areas = [t for t, c in sorted_tags[:5]]
        target = topic if topic else ", ".join(weak_areas) if weak_areas else "ì¼ë°˜ ì•Œê³ ë¦¬ì¦˜"

        api_key, model = _get_user_llm_key(db, user_id)
        from merge_core.llm import generate_text

        system_prompt = """ë„ˆëŠ” ì•Œê³ ë¦¬ì¦˜ í€´ì¦ˆ ì¶œì œìë‹¤. ì‚¬ìš©ìì˜ ì·¨ì•½ ë¶„ì•¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµì— ë„ì›€ì´ ë˜ëŠ” í€´ì¦ˆë¥¼ ì¶œì œí•œë‹¤.

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ í€´ì¦ˆ 3ë¬¸ì œë¥¼ ì¶œì œí•´ë¼:

## í€´ì¦ˆ 1: (ë‚œì´ë„)
**ë¬¸ì œ:** (ë¬¸ì œ ì„¤ëª…)
**íŒíŠ¸:** (ì ‘ê·¼ ë°©ë²• íŒíŠ¸)

<details>
<summary>ì •ë‹µ ë³´ê¸°</summary>

**í’€ì´:** (ìƒì„¸í•œ í’€ì´ ê³¼ì •)
**í•µì‹¬ ê°œë…:** (ì´ ë¬¸ì œì—ì„œ ë°°ìš¸ ìˆ˜ ìˆëŠ” í•µì‹¬ ê°œë…)
**ìœ ì‚¬ ë¬¸ì œ ì¶”ì²œ:** (ë°±ì¤€/í”„ë¡œê·¸ë˜ë¨¸ìŠ¤ ë¬¸ì œ ë²ˆí˜¸)
</details>

ê° ë¬¸ì œëŠ” ì„œë¡œ ë‹¤ë¥¸ ë‚œì´ë„(ì‰¬ì›€/ë³´í†µ/ì–´ë ¤ì›€)ë¡œ ì¶œì œí•´ë¼.
í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³ , ì‹¤ì œ ì½”ë”© ì¸í„°ë·°ì— ë‚˜ì˜¬ ë²•í•œ ì‹¤ìš©ì ì¸ ë¬¸ì œë¥¼ ë‚´ë¼."""

        user_prompt = f"""íƒ€ê²Ÿ ì£¼ì œ: {target}
í˜„ì¬ í’€ì´ í†µê³„: {dict(list(all_tags.items())[:15])}

ì´ ì‚¬ìš©ìì˜ ì·¨ì•½ ë¶„ì•¼ë¥¼ ë³´ì™„í•  ìˆ˜ ìˆëŠ” í€´ì¦ˆ 3ë¬¸ì œë¥¼ ì¶œì œí•´ì£¼ì„¸ìš”."""

        quiz = generate_text(system_prompt, user_prompt, model=model, api_key=api_key)

        content = GeneratedContent(
            user_id=user_id,
            content_type="coach_quiz",
            title=f"ì½”ë”© í€´ì¦ˆ â€” {target}",
            content=quiz,
            status="completed",
            metadata={"topic": target},
        )
        db.add(content)
        db.commit()

        return {"status": "success", "content_id": str(content.id), "quiz": quiz}
    except Exception as e:
        return {"error": str(e)}
    finally:
        db.close()


@celery_app.task
def generate_resume(user_id: str, resume_type: str = "resume", extra_context: str = ""):
    """Generate resume or cover letter from portfolio data."""
    db = SessionLocal()
    try:
        from app.models.repo import Repo
        from app.models.commit import Commit
        from app.models.problem import Problem
        from app.models.blog_post import BlogPost
        from app.models.user_profile import UserProfile
        from sqlalchemy import func, desc

        user = db.query(User).filter(User.id == user_id).first()
        if not user:
            return {"error": "User not found"}

        profile = db.query(UserProfile).filter(UserProfile.user_id == user_id).first()

        # Gather portfolio data
        repos = db.query(Repo).filter(Repo.user_id == user_id).order_by(desc(Repo.stars)).limit(10).all()
        total_commits = db.query(func.count(Commit.id)).filter(Commit.user_id == user_id).scalar() or 0
        total_problems = db.query(func.count(Problem.id)).filter(Problem.user_id == user_id).scalar() or 0
        total_blogs = db.query(func.count(BlogPost.id)).filter(BlogPost.user_id == user_id).scalar() or 0

        # Language stats
        lang_stats = {}
        for r in repos:
            if r.language:
                lang_stats[r.language] = lang_stats.get(r.language, 0) + 1

        # Problem tags
        problems = db.query(Problem).filter(Problem.user_id == user_id).all()
        tag_counts = {}
        for p in problems:
            for t in (p.tags or []):
                tag_counts[t] = tag_counts.get(t, 0) + 1

        portfolio_text = f"""ì´ë¦„: {profile.portfolio_name or user.name or "ê°œë°œì"}
ì´ë©”ì¼: {profile.portfolio_email or user.email}
ìê¸°ì†Œê°œ: {profile.portfolio_bio or ""}

GitHub í”„ë¡œì íŠ¸ ({len(repos)}ê°œ):
""" + "\n".join([
            f"- {r.full_name}: {r.description or 'ì„¤ëª… ì—†ìŒ'} ({r.language or '?'}, â­{r.stars or 0})"
            for r in repos
        ]) + f"""

ì´ ì»¤ë°‹ ìˆ˜: {total_commits}
ì•Œê³ ë¦¬ì¦˜ í’€ì´ ìˆ˜: {total_problems}
ë¸”ë¡œê·¸ ê¸€ ìˆ˜: {total_blogs}
ì£¼ìš” ì–¸ì–´: {dict(sorted(lang_stats.items(), key=lambda x: x[1], reverse=True)[:5])}
ì•Œê³ ë¦¬ì¦˜ ìœ í˜•: {dict(sorted(tag_counts.items(), key=lambda x: x[1], reverse=True)[:10])}"""

        api_key, model = _get_user_llm_key(db, user_id)
        from merge_core.llm import generate_text

        if resume_type == "cover_letter":
            system_prompt = """ë„ˆëŠ” IT/ê°œë°œì ì±„ìš© ì „ë¬¸ ìê¸°ì†Œê°œì„œ ì‘ì„± ë„ìš°ë¯¸ë‹¤.
ì‚¬ìš©ìì˜ í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹¤ì œ ì±„ìš©ì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìê¸°ì†Œê°œì„œë¥¼ ì‘ì„±í•œë‹¤.

ë‹¤ìŒ êµ¬ì¡°ë¡œ ì‘ì„±í•´ë¼:
## ìê¸°ì†Œê°œì„œ

### 1. ì„±ì¥ ê³¼ì • ë° ì§€ì› ë™ê¸°
(ê°œë°œì„ ì‹œì‘í•˜ê²Œ ëœ ê³„ê¸°ì™€ ì„±ì¥ ê³¼ì •)

### 2. ê¸°ìˆ  ì—­ëŸ‰
(ì£¼ìš” ê¸°ìˆ  ìŠ¤íƒê³¼ í”„ë¡œì íŠ¸ ê²½í—˜ì„ êµ¬ì²´ì ìœ¼ë¡œ)

### 3. í”„ë¡œì íŠ¸ ê²½í—˜
(ê°€ì¥ ì˜ë¯¸ ìˆëŠ” í”„ë¡œì íŠ¸ 2-3ê°œ ìƒì„¸ ì„¤ëª…)

### 4. ì„±ì¥ ê°€ëŠ¥ì„±
(ìê¸° ê³„ë°œ ë…¸ë ¥ê³¼ ì•ìœ¼ë¡œì˜ ê³„íš)

í•œêµ­ì–´ë¡œ, êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ ê²½í—˜ì„ í¬í•¨í•˜ì—¬ ì‘ì„±í•´ë¼. ë¶„ëŸ‰ì€ 1000-1500ì."""
        else:
            system_prompt = """ë„ˆëŠ” IT/ê°œë°œì ì´ë ¥ì„œ ì‘ì„± ì „ë¬¸ê°€ë‹¤.
ì‚¬ìš©ìì˜ í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê¹”ë”í•˜ê³  ì „ë¬¸ì ì¸ ì´ë ¥ì„œë¥¼ Markdown í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•œë‹¤.

ë‹¤ìŒ êµ¬ì¡°ë¡œ ì‘ì„±í•´ë¼:
# ì´ë ¥ì„œ

## ì¸ì ì‚¬í•­
(ì´ë¦„, ì´ë©”ì¼, GitHub ë“±)

## ê¸°ìˆ  ìŠ¤íƒ
(í”„ë¡œê·¸ë˜ë° ì–¸ì–´, í”„ë ˆì„ì›Œí¬, ë„êµ¬ ë“±ì„ ìˆ™ë ¨ë„ ìˆœìœ¼ë¡œ)

## í”„ë¡œì íŠ¸ ê²½í—˜
(ê° í”„ë¡œì íŠ¸: ì´ë¦„, ì„¤ëª…, ê¸°ìˆ  ìŠ¤íƒ, ì£¼ìš” ê¸°ì—¬, ê²°ê³¼/ì„±ê³¼)

## ì•Œê³ ë¦¬ì¦˜/PS
(solved.ac í†µê³„, ì£¼ìš” ì•Œê³ ë¦¬ì¦˜ ìœ í˜•)

## ê¸°ìˆ  ë¸”ë¡œê·¸
(ë¸”ë¡œê·¸ í™œë™ ì†Œê°œ)

í•œêµ­ì–´ë¡œ, ì‹¤ì œ ì±„ìš© ì‹œì¥ì—ì„œ í†µí•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ë¼."""

        user_prompt = f"""{portfolio_text}

{f"ì¶”ê°€ ìš”ì²­ì‚¬í•­: {extra_context}" if extra_context else ""}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ {'ìê¸°ì†Œê°œì„œ' if resume_type == 'cover_letter' else 'ì´ë ¥ì„œ'}ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”."""

        result = generate_text(system_prompt, user_prompt, model=model, api_key=api_key)

        content = GeneratedContent(
            user_id=user_id,
            content_type=resume_type,
            title="ì´ë ¥ì„œ" if resume_type == "resume" else "ìê¸°ì†Œê°œì„œ",
            content=result,
            status="completed",
            metadata={"resume_type": resume_type},
        )
        db.add(content)
        db.commit()

        return {"status": "success", "content_id": str(content.id), "content": result}
    except Exception as e:
        return {"error": str(e)}
    finally:
        db.close()
